{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Publications markdown generator for academicpages\n",
    "\n",
    "Takes a TSV of publications with metadata and converts them for use with [academicpages.github.io](academicpages.github.io). This is an interactive Jupyter notebook ([see more info here](http://jupyter-notebook-beginner-guide.readthedocs.io/en/latest/what_is_jupyter.html)). The core python code is also in `publications.py`. Run either from the `markdown_generator` folder after replacing `publications.tsv` with one containing your data.\n",
    "\n",
    "TODO: Make this work with BibTex and other databases of citations, rather than Stuart's non-standard TSV format and citation style.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data format\n",
    "\n",
    "The TSV needs to have the following columns: pub_date, title, venue, excerpt, citation, site_url, and paper_url, with a header at the top. \n",
    "\n",
    "- `excerpt` and `paper_url` can be blank, but the others must have values. \n",
    "- `pub_date` must be formatted as YYYY-MM-DD.\n",
    "- `url_slug` will be the descriptive part of the .md file and the permalink URL for the page about the paper. The .md file will be `YYYY-MM-DD-[url_slug].md` and the permalink will be `https://[yourdomain]/publications/YYYY-MM-DD-[url_slug]`\n",
    "\n",
    "This is how the raw file looks (it doesn't look pretty, use a spreadsheet or other program to edit and create)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pub_date\ttitle\tvenue\t excerpt\tcitation\turl_slug\tpaper_url\n",
      "2023-01-01\tBayesian Clustering of n-gons via a Double Dirichlet Mixture Model\tJournal of the American Statistical Association\tThe explosion of deep learning in medical image analysis has enabled the efficient abstraction of detailed biological shapes from medical images, creating an abundance of often-unlabeled biological shape datasets. Statistical characterization of these shapes is vital to medical image analysis and has informed clinical diagnosis; thus, as medical images grow increasingly larger and more detailed, there is a need for transparent statistical approaches to biological shape analysis that complement deep learning methods. Clustering is an unsupervised technique that partitions a dataset into similar subsets and has myriad medical applications. Attempting to cluster shapes presents unique challenges, including the need for shape representations that retain maximal geometric information. This study aims to develop a robust transformation- invariant Bayesian shape clustering method that represents biological shapes as n-gons and clusters their intrinsic properties by approximating parameters as defined through a double Dirichlet mixture model. The model is also generalizable to non-biological shapes.\tJin et al. (2023). \"Bayesian Clustering of n-gons via a Double Dirichlet Mixture Model.\" <i>Journal of the American Statistical Association</i>. 1(1).\tbacon\n",
      "2023-01-01\tDeep learning-based measurement of murine bone length in X-ray images\tScientific Reports\tWe developed a Keypoint R-CNN pipeline to measure the bone length of mice in X-ray images.\tRong et al. (2023). \"Deep learning-based measurement of murine bone length in X-ray images.\" <i>Scientific Reports</i>. 1(2).\tbone-length\n",
      "2022-12-08\tA Deep Learning Approach for Histology-Based Nuclei Segmentation and Tumor Microenvironment Characterization\tModern Pathology\tMicroscopic examination of pathology slides is essential to disease diagnosis and biomedical research; however, traditional manual examination of tissue slides is laborious and subjective. Tumor whole-slide image (WSI) scanning is becoming part of routine clinical procedure and produces massive data that capture tumor histological details at high resolution. Furthermore, the rapid development of deep learning algorithms has significantly increased the efficiency and accuracy of pathology image analysis. In light of this progress, digital pathology is fast becoming a powerful tool to assist pathologists. Studying tumor tissue and its surrounding microenvironment provides critical insight into tumor initiation, progression, metastasis, and potential therapeutic targets. Nuclei segmentation and classification are critical to pathology image analysis, especially in characterizing and quantifying the tumor microenvironment (TME). Computational algorithms have been developed for nuclei segmentation and TME quantification within image patches; however, existing algorithms are computationally intensive and time-consuming for WSI analysis.  In this study, we present Histology-based Detection using Yolo (HD-Yolo), a new method that significantly accelerates nuclei segmentation and TME quantification. We demonstrate that HD-Yolo outperforms existing methods for WSI analysis in nuclei detection and classification accuracy, as well as computation time. The WSI analysis pipeline and a real-time nuclei-segmentation viewer is available at (https://github.com/impromptuRong/hd_wsi).\tRong et al. (2023). \"A Deep Learning Approach for Histology-Based Nuclei Segmentation and Tumor Microenvironment Characterization.\" <i>Modern Pathology</i>. 1(3).\thd-yolo\n",
      "2023-01-01\tA deep learning-based Onion Peeling algorithm for measurement of oral epithelium layer number\tCancers\tOral cavity and pharyngeal cancer is a common, complex cancer that significantly affects patientsâ€™ quality of life. Early diagnosis typically improves prognoses yet relies on pathologist examination of histology images that exhibits high inter- and intra-observer variation. The advent of deep learning has automated this analysis, notably with object segmentation. However, techniques for automated oral dysplasia diagnosis have been limited to shape or cell stain information, without addressing the diagnostic potential in counting the number of cell layers in the oral epithelium. Our study attempts to address this gap by combining the existing U-Net and HD-Staining architectures for segmenting the oral epithelium and introducing a novel algorithm that we call Onion Peeling for counting the epithelium layer number. Experimental results show a close correlation between our algorithmic and expert manual layer counts, demonstrating the feasibility of automated layer counting. We also show the clinical relevance of oral epithelial layer number to grading oral dysplasia severity through survival analysis. Overall, our study shows that automated counting of oral epithelium layers can represent a potential addition to the digital pathology toolbox. Model generalizability and accuracy could be improved further with a larger training dataset.\tZhang et al. (2023). \"A deep learning-based Onion Peeling algorithm for measurement of oral epithelium layer number.\" <i>Cancers</i>. 1(4).\tonion-peeling\n",
      "2023-02-15\tDeep Learning-Based Hepatic Ploidy Quantification Using H&E Histopathology Images\tGenes\tPolyploidy, or whole number genome duplications within a single cell, is an important charac-teristic of cells in many tissues such as the heart, muscle, blood, and liver. In the liver, many hepatocytes are polyploid. Recent studies have shown that the extent and frequency of polyploidy in hepatocytes are correlated with liver disease progression. In this study, we developed an im-age-based computational algorithm to characterize hepatic ploidy for individual patients. It quantifies ploidy information using hematoxylin-eosin (H&E) histopathology images, which are widely obtained during routine clinical practice. A deep learning model is used to segment and classify different types of cell nuclei on H&E histopathology images. Based on the identified hepatocyte nuclei, the algorithm calculates both cellular ploidy and nuclear ploidy. This algo-rithm allows users to establish the total number of hepatocytes and detailed ploidy of each hepatocyte in a region of interest (ROI), and therefore facilitates our understanding of polyploidy in human liver disease.\tWen et al. (2023). \"Deep Learning-Based Hepatic Ploidy Quantification Using H&E Histopathology Images.\" <i>Genes</i>. 1(4).\thepatic-ploidy\t\n"
     ]
    }
   ],
   "source": [
    "!cat publications.tsv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import pandas\n",
    "\n",
    "We are using the very handy pandas library for dataframes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import TSV\n",
    "\n",
    "Pandas makes this easy with the read_csv function. We are using a TSV, so we specify the separator as a tab, or `\\t`.\n",
    "\n",
    "I found it important to put this data in a tab-separated values format, because there are a lot of commas in this kind of data and comma-separated values can get messed up. However, you can modify the import statement, as pandas also has read_excel(), read_json(), and others."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pub_date</th>\n",
       "      <th>title</th>\n",
       "      <th>venue</th>\n",
       "      <th>excerpt</th>\n",
       "      <th>citation</th>\n",
       "      <th>url_slug</th>\n",
       "      <th>paper_url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023-01-01</td>\n",
       "      <td>Bayesian Clustering of n-gons via a Double Dir...</td>\n",
       "      <td>Journal of the American Statistical Association</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Jin et al. (2023). \"Bayesian Clustering of n-g...</td>\n",
       "      <td>bacon</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2023-01-01</td>\n",
       "      <td>Deep learning-based measurement of murine bone...</td>\n",
       "      <td>Scientific Reports</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Rong et al. (2023). \"Deep learning-based measu...</td>\n",
       "      <td>bone-length</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2022-12-08</td>\n",
       "      <td>A Deep Learning Approach for Histology-Based N...</td>\n",
       "      <td>Modern Pathology</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Rong et al. (2023). \"A Deep Learning Approach ...</td>\n",
       "      <td>hd-yolo</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2023-01-01</td>\n",
       "      <td>A deep learning-based Onion Peeling algorithm ...</td>\n",
       "      <td>Cancers</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Zhang et al. (2023). \"A deep learning-based On...</td>\n",
       "      <td>onion-peeling</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2023-02-15</td>\n",
       "      <td>Deep Learning-Based Hepatic Ploidy Quantificat...</td>\n",
       "      <td>Genes</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Wen et al. (2023). \"Deep Learning-Based Hepati...</td>\n",
       "      <td>hepatic-ploidy</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     pub_date                                              title  \\\n",
       "0  2023-01-01  Bayesian Clustering of n-gons via a Double Dir...   \n",
       "1  2023-01-01  Deep learning-based measurement of murine bone...   \n",
       "2  2022-12-08  A Deep Learning Approach for Histology-Based N...   \n",
       "3  2023-01-01  A deep learning-based Onion Peeling algorithm ...   \n",
       "4  2023-02-15  Deep Learning-Based Hepatic Ploidy Quantificat...   \n",
       "\n",
       "                                             venue   excerpt  \\\n",
       "0  Journal of the American Statistical Association       NaN   \n",
       "1                               Scientific Reports       NaN   \n",
       "2                                 Modern Pathology       NaN   \n",
       "3                                          Cancers       NaN   \n",
       "4                                            Genes       NaN   \n",
       "\n",
       "                                            citation        url_slug  \\\n",
       "0  Jin et al. (2023). \"Bayesian Clustering of n-g...           bacon   \n",
       "1  Rong et al. (2023). \"Deep learning-based measu...     bone-length   \n",
       "2  Rong et al. (2023). \"A Deep Learning Approach ...         hd-yolo   \n",
       "3  Zhang et al. (2023). \"A deep learning-based On...   onion-peeling   \n",
       "4  Wen et al. (2023). \"Deep Learning-Based Hepati...  hepatic-ploidy   \n",
       "\n",
       "   paper_url  \n",
       "0        NaN  \n",
       "1        NaN  \n",
       "2        NaN  \n",
       "3        NaN  \n",
       "4        NaN  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "publications = pd.read_csv(\"publications.tsv\", sep=\"\\t\", header=0)\n",
    "publications\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Escape special characters\n",
    "\n",
    "YAML is very picky about how it takes a valid string, so we are replacing single and double quotes (and ampersands) with their HTML encoded equivilents. This makes them look not so readable in raw format, but they are parsed and rendered nicely."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "html_escape_table = {\n",
    "    \"&\": \"&amp;\",\n",
    "    '\"': \"&quot;\",\n",
    "    \"'\": \"&apos;\"\n",
    "    }\n",
    "\n",
    "def html_escape(text):\n",
    "    \"\"\"Produce entities within text.\"\"\"\n",
    "    return \"\".join(html_escape_table.get(c,c) for c in text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating the markdown files\n",
    "\n",
    "This is where the heavy lifting is done. This loops through all the rows in the TSV dataframe, then starts to concatentate a big string (```md```) that contains the markdown for each type. It does the YAML metadata first, then does the description for the individual page."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "for row, item in publications.iterrows():\n",
    "    \n",
    "    md_filename = str(item.pub_date) + \"-\" + item.url_slug + \".md\"\n",
    "    html_filename = str(item.pub_date) + \"-\" + item.url_slug\n",
    "    year = item.pub_date[:4]\n",
    "    \n",
    "    ## YAML variables\n",
    "    \n",
    "    md = \"---\\ntitle: \\\"\"   + item.title + '\"\\n'\n",
    "    \n",
    "    md += \"\"\"collection: publications\"\"\"\n",
    "    \n",
    "    md += \"\"\"\\npermalink: /publication/\"\"\" + html_filename\n",
    "    \n",
    "    #if len(str(item.excerpt)) > 5:\n",
    "    #    md += \"\\nexcerpt: '\" + html_escape(item.excerpt) + \"'\"\n",
    "    \n",
    "    md += \"\\ndate: \" + str(item.pub_date) \n",
    "    \n",
    "    md += \"\\nvenue: '\" + html_escape(item.venue) + \"'\"\n",
    "    \n",
    "    if len(str(item.paper_url)) > 5:\n",
    "        md += \"\\npaperurl: '\" + item.paper_url + \"'\"\n",
    "    \n",
    "    md += \"\\ncitation: '\" + html_escape(item.citation) + \"'\"\n",
    "    \n",
    "    md += \"\\n---\"\n",
    "    \n",
    "    ## Markdown description for individual page\n",
    "        \n",
    "    #if len(str(item.excerpt)) > 5:\n",
    "    #    md += \"\\n\" + html_escape(item.excerpt) + \"\\n\"\n",
    "    \n",
    "    if len(str(item.paper_url)) > 5:\n",
    "        md += \"\\n[Download paper here](\" + item.paper_url + \")\\n\" \n",
    "        \n",
    "    md += \"\\nRecommended citation: \" + item.citation\n",
    "    \n",
    "    md_filename = os.path.basename(md_filename)\n",
    "       \n",
    "    with open(\"../_publications/\" + md_filename, 'w') as f:\n",
    "        f.write(md)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These files are in the publications directory, one directory below where we're working from."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-12-08-hd-yolo.md        2023-01-01-onion-peeling.md\n",
      "2023-01-01-bacon.md          2023-02-15-hepatic-ploidy.md\n",
      "2023-01-01-bone-length.md\n"
     ]
    }
   ],
   "source": [
    "!ls ../_publications/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---\n",
      "title: \"A Deep Learning Approach for Histology-Based Nuclei Segmentation and Tumor Microenvironment Characterization\"\n",
      "collection: publications\n",
      "permalink: /publication/2022-12-08-hd-yolo\n",
      "date: 2022-12-08\n",
      "venue: 'Modern Pathology'\n",
      "citation: 'Rong et al. (2023). &quot;A Deep Learning Approach for Histology-Based Nuclei Segmentation and Tumor Microenvironment Characterization.&quot; <i>Modern Pathology</i>. 1(3).'\n",
      "---\n",
      "Recommended citation: Rong et al. (2023). \"A Deep Learning Approach for Histology-Based Nuclei Segmentation and Tumor Microenvironment Characterization.\" <i>Modern Pathology</i>. 1(3)."
     ]
    }
   ],
   "source": [
    "!cat ../_publications/2022-12-08-hd-yolo.md"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "vscode": {
   "interpreter": {
    "hash": "b0fa6594d8f4cbf19f97940f81e996739fb7646882a419484c72d19e05852a7e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
